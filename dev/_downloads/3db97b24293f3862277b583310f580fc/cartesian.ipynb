{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Gridding and upward continuation\n\nMost potential field surveys gather data along scattered and uneven flight\nlines or ground measurements. For a great number of applications we may need to\ninterpolate these data points onto a regular grid at a constant altitude.\nUpward-continuation is also a routine task for smoothing, noise attenuation,\nsource separation, etc.\n\nBoth tasks can be done simultaneously through an *equivalent sources*\n[Dampney1969]_ (a.k.a *equivalent layer*). We will use\n:class:`harmonica.EquivalentSources` to estimate the coefficients of a set of\npoint sources that fit the observed data. The fitted sources can then be used\nto predict data values wherever we want, like on a grid at a certain altitude.\nBy default, the sources for :class:`~harmonica.EquivalentSources` are placed\none beneath each data point at a relative depth from the elevation of the data\npoint following [Cordell1992]_.\n\nThe advantage of using equivalent sources is that it takes into account the 3D\nnature of the observations, not just their horizontal positions. It also allows\ndata uncertainty to be taken into account and noise to be suppressed though the\nleast-squares fitting process. The main disadvantage is the increased\ncomputational load (both in terms of time and memory).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import ensaio\nimport pandas as pd\nimport pygmt\nimport pyproj\nimport verde as vd\n\nimport harmonica as hm\n\n# Fetch the sample total-field magnetic anomaly data from Great Britain\nfname = ensaio.fetch_britain_magnetic(version=1)\ndata = pd.read_csv(fname)\n\n# Slice a smaller portion of the survey data to speed-up calculations for this\n# example\nregion = [-5.5, -4.7, 57.8, 58.5]\ninside = vd.inside((data.longitude, data.latitude), region)\ndata = data[inside]\nprint(\"Number of data points:\", data.shape[0])\nprint(\"Mean height of observations:\", data.height_m.mean())\n\n# Since this is a small area, we'll project our data and use Cartesian\n# coordinates\nprojection = pyproj.Proj(proj=\"merc\", lat_ts=data.latitude.mean())\neasting, northing = projection(data.longitude.values, data.latitude.values)\ncoordinates = (easting, northing, data.height_m)\nxy_region = vd.get_region((easting, northing))\n\n# Create the equivalent sources.\n# We'll use the default point source configuration at a relative depth beneath\n# each observation point.\n# The damping parameter helps smooth the predicted data and ensure stability.\neqs = hm.EquivalentSources(depth=1000, damping=1)\n\n# Fit the sources coefficients to the observed magnetic anomaly.\neqs.fit(coordinates, data.total_field_anomaly_nt)\n\n# Evaluate the data fit by calculating an R\u00b2 score against the observed data.\n# This is a measure of how well the sources fit the data, NOT how good the\n# interpolation will be.\nprint(\"R\u00b2 score:\", eqs.score(coordinates, data.total_field_anomaly_nt))\n\n# Interpolate data on a regular grid with 500 m spacing. The interpolation\n# requires the height of the grid points (upward coordinate). By passing in\n# 1500 m, we're effectively upward-continuing the data (mean flight height is\n# 500 m).\n\ngrid_coords = vd.grid_coordinates(region=xy_region, spacing=500, extra_coords=1500)\n\ngrid = eqs.grid(coordinates=grid_coords, data_names=[\"magnetic_anomaly\"])\n\n# The grid is a xarray.Dataset with values, coordinates, and metadata\nprint(\"\\nGenerated grid:\\n\", grid)\n\n# Set figure properties\nw, e, s, n = xy_region\nfig_height = 10\nfig_width = fig_height * (e - w) / (n - s)\nfig_ratio = (n - s) / (fig_height / 100)\nfig_proj = f\"x1:{fig_ratio}\"\n\n# Plot original magnetic anomaly and the gridded and upward-continued version\nfig = pygmt.Figure()\n\ntitle = \"Observed magnetic anomaly data\"\n\n# Make colormap of data\n# Get the 95 percentile of the maximum absolute value between the original and\n# gridded data so we can use the same color scale for both plots and have 0\n# centered at the white color.\nmaxabs = vd.maxabs(data.total_field_anomaly_nt, grid.magnetic_anomaly.values) * 0.95\npygmt.makecpt(\n    cmap=\"vik\",\n    series=(-maxabs, maxabs),\n    background=True,\n)\n\nwith pygmt.config(FONT_TITLE=\"12p\"):\n    fig.plot(\n        projection=fig_proj,\n        region=xy_region,\n        frame=[f\"WSne+t{title}\", \"xa10000\", \"ya10000\"],\n        x=easting,\n        y=northing,\n        fill=data.total_field_anomaly_nt,\n        style=\"c0.1c\",\n        cmap=True,\n    )\n\nfig.colorbar(cmap=True, frame=[\"a400f100\", \"x+lnT\"])\n\nfig.shift_origin(xshift=fig_width + 1)\n\ntitle = \"Gridded and upward-continued\"\n\nwith pygmt.config(FONT_TITLE=\"12p\"):\n    fig.grdimage(\n        frame=[f\"ESnw+t{title}\", \"xa10000\", \"ya10000\"],\n        grid=grid.magnetic_anomaly,\n        cmap=True,\n    )\n\nfig.colorbar(cmap=True, frame=[\"a400f100\", \"x+lnT\"])\n\nfig.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}